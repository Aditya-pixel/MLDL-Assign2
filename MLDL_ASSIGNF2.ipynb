{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MLDL ASSIGNF2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya-pixel/MLDL-Assign2/blob/master/MLDL_ASSIGNF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYO22MvR0oF8",
        "colab_type": "code",
        "outputId": "6227f64c-9420-4d58-b78a-ed06b4885158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from skimage.data import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import os\n",
        "import random\n",
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import Input\n",
        "import io\n",
        "from io import StringIO\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os, cv2, re, random\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.nn as nn #neural networks mool\n",
        "import torchvision #used for visualizing things editing data etc\n",
        "import torchvision.transforms as transforms #cropping fitting etc\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRGZypqLEXhq",
        "colab_type": "code",
        "outputId": "d1f38ea3-9529-436d-d65a-afe1de6d3a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/9988/868324/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1577886011&Signature=MLzxpskBhRMhqAtOZW788b%2FfLHVVkS6rVm2SOK9noJnOC40MnGSaSxD2UpqGFSPDFDtH%2FkLygegnIuGXGyXBZOyosFsveDoQAxZUAp2Bx7jTP5S7WfXbqNiYssqcNMNuzRfv%2F9x6wUi7UYbmIDePbiOK61d4I8Oo3TvOsapY7w7WcgnC78msKaKP2aX%2FwsmwdqhnLF1muqYX%2BYRFHWAg4LaZScSPx02QlnWEABcMNwGgL8Tt0oC2FXq6VJfO6AqjzX9RjHcve3ivfnq7Qqlhaf30avXCSOf7%2BBeW4isoeU0AmBGV%2B8f%2Fbo%2FDxhqT9zw9bZ3oK5jWfZ5Ft9uWgWBlSg%3D%3D&response-content-disposition=attachment%3B+filename%3Dairbus-ship-detection.zip\" -O \"airbus-ship-detection.zip\" -c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-29 13:42:25--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/9988/868324/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1577886011&Signature=MLzxpskBhRMhqAtOZW788b%2FfLHVVkS6rVm2SOK9noJnOC40MnGSaSxD2UpqGFSPDFDtH%2FkLygegnIuGXGyXBZOyosFsveDoQAxZUAp2Bx7jTP5S7WfXbqNiYssqcNMNuzRfv%2F9x6wUi7UYbmIDePbiOK61d4I8Oo3TvOsapY7w7WcgnC78msKaKP2aX%2FwsmwdqhnLF1muqYX%2BYRFHWAg4LaZScSPx02QlnWEABcMNwGgL8Tt0oC2FXq6VJfO6AqjzX9RjHcve3ivfnq7Qqlhaf30avXCSOf7%2BBeW4isoeU0AmBGV%2B8f%2Fbo%2FDxhqT9zw9bZ3oK5jWfZ5Ft9uWgWBlSg%3D%3D&response-content-disposition=attachment%3B+filename%3Dairbus-ship-detection.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30690510746 (29G) [application/zip]\n",
            "Saving to: ‘airbus-ship-detection.zip’\n",
            "\n",
            "airbus-ship-detecti 100%[===================>]  28.58G  42.6MB/s    in 8m 11s  \n",
            "\n",
            "2019-12-29 13:50:36 (59.6 MB/s) - ‘airbus-ship-detection.zip’ saved [30690510746/30690510746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQRkuJFmJDl",
        "colab_type": "code",
        "outputId": "f8aa25e4-5eb0-4875-cba4-c4c0bcdc9b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import gc\n",
        "print(os.listdir(\"/content\"))\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import time\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'airbus-ship-detection.zip', 'sample_data']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxv_GAy2nRRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/airbus-ship-detection.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCmyJ8sUoMt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/train_ship_segmentations_v2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQIxodE23Zl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ships = train[~train.EncodedPixels.isna()].ImageId.unique()\n",
        "noships = train[train.EncodedPixels.isna()].ImageId.unique()\n",
        "\n",
        "plt.bar(['Ships', 'No Ships'], [len(ships), len(noships)]);\n",
        "plt.ylabel('Number of Images');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd-X9oATd1Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['exist_ship'] = train['EncodedPixels'].fillna(0)\n",
        "train.loc[train['exist_ship'] != 0 , 'exist_ship'] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paG_YEoHeNC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "Train_path = '/content/train_v2'\n",
        "Test_path = '/content/test_v2'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSaqK8aBg_La",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gp = train.groupby(['ImageId']).sum().reset_index()\n",
        "train_gp.loc[train_gp['exist_ship']>0,'exist_ship']=1\n",
        "\n",
        "train_sample = train_gp.sample(5000)\n",
        "test_sample = train_gp.sample(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxtnNQTtgLa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path):\n",
        "    files_array = []\n",
        "    if str(path) == str(Train_path):\n",
        "        data = np.array(train_sample['ImageId'])\n",
        "        data_targets = np_utils.to_categorical(np.array(train_sample['exist_ship']), 133)\n",
        "\n",
        "        for idx, element in  enumerate(data): \n",
        "            files_array.append(Train_path + element)\n",
        "\n",
        "        data = np.array(files_array)\n",
        "    else:\n",
        "        data = np.array(test_sample['ImageId'])\n",
        "        data_targets = np_utils.to_categorical(np.array(test_sample['exist_ship']), 133)\n",
        "\n",
        "        for idx, element in  enumerate(data): \n",
        "            files_array.append(Train_path + element)\n",
        "\n",
        "        data = np.array(files_array)\n",
        "    \n",
        "    return data, data_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVqLOpwvgUcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files, train_targets = load_dataset(Train_path)\n",
        "test_files, test_targets = load_dataset(Test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyzn2Dz6gaYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image \n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-VF4NUbhOUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile                            \n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBdkzcj4iJ2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import genfromtxt\n",
        "train_data = genfromtxt('/content/train_ship_segmentations_v2.csv', delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ENiITcm4Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input((768, 768, 3))\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(768,768,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('softmax'))\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='mean_squared_error', optimizer=sgd)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9h7uyB7jQL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
        "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L_Dd3CUi3kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "START = 0.5\n",
        "END = 0.95\n",
        "STEP = 0.05\n",
        "N_STEPS = int((END - START) / STEP) + 2\n",
        "DEFAULT_THRESHOLDS = np.linspace(START, END, N_STEPS)\n",
        "DEFAULT_BETA = 1\n",
        "DEFAULT_LOGS = {}\n",
        "FBETA_METRIC_NAME = \"val_fbeta\"\n",
        "\n",
        "# Some unit test constants\n",
        "input_dim = 2\n",
        "num_hidden = 4\n",
        "num_classes = 2\n",
        "batch_size = 5\n",
        "train_samples = 20\n",
        "test_samples = 20\n",
        "SEED = 42\n",
        "TEST_BETA = 2\n",
        "EPOCHS = 5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Notice that this callback only works with Keras 2.0.0\n",
        "\n",
        "\n",
        "class FBetaMetricCallback(Callback):\n",
        "\n",
        "    def __init__(self, beta=DEFAULT_BETA, thresholds=DEFAULT_THRESHOLDS):\n",
        "        self.beta = beta\n",
        "        self.thresholds = thresholds\n",
        "        # Will be initialized when the training starts\n",
        "        self.val_fbeta = None\n",
        "\n",
        "    def on_train_begin(self, logs=DEFAULT_LOGS):\n",
        "        \"\"\" This is where the validation Fbeta\n",
        "        validation scores will be saved during training: one value per\n",
        "        epoch.\n",
        "        \"\"\"\n",
        "        self.val_fbeta = []\n",
        "\n",
        "    def _score_per_threshold(self, predictions, targets, threshold):\n",
        "        \"\"\" Compute the Fbeta score per threshold.\n",
        "        \"\"\"\n",
        "        \n",
        "        thresholded_predictions = (predictions > threshold).astype(int)\n",
        "        return fbeta_score(targets, thresholded_predictions, beta=self.beta, average='micro')\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=DEFAULT_LOGS):\n",
        "        val_predictions = self.model.predict(self.validation_data[0])\n",
        "        val_targets = self.validation_data[1]\n",
        "        _val_fbeta = np.mean([self._score_per_threshold(val_predictions,\n",
        "                                                        val_targets, threshold)\n",
        "                              for threshold in self.thresholds])\n",
        "        self.val_fbeta.append(_val_fbeta)\n",
        "        print(\"Current F{} metric is: {}\".format(str(self.beta), str(_val_fbeta)))\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs=DEFAULT_LOGS):\n",
        "        \"\"\" Assign the validation Fbeta computed metric to the History object.\n",
        "        \"\"\"\n",
        "        self.model.history.history[FBETA_METRIC_NAME] = self.val_fbeta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKEqOkEpi9l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint  \n",
        "\n",
        "epochs = 20\n",
        "\n",
        "fbeta_metric_callback = FBetaMetricCallback(beta=2)\n",
        "history = model.fit(train_tensors, train_targets, \n",
        "          validation_data=(test_tensors, test_targets),\n",
        "          epochs=epochs, batch_size=20, callbacks=[fbeta_metric_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}